http://www.gaminggroove.com/article.php?id=27
Talking nasty with Tim Sweeney  
Tim Sweeney going deep into language and 3D technology territory
Gaming Groove
Billy "Wicked" Wilson

<desc>Tim 'The Man' Sweeney should require no introduction around here, but in case you didn't know and were afraid to ask, Tim is of course our favorite Founder and President of Epic Games, and he's been known to toss the old C++ compiler around for a spin, every now and then :) Today Tim goes deep into language and 3D technology territory: </desc>

<q>With hardware rendering speed growing at a rapid pace, how much of an extra strain is this putting on the art developers to keep up? Are there any unique custom tools that the latest Unreal Engine comes with that you are especially proud of?</q>

<a>Art requirements are going up dramatically with the coming generation. The content we're building in Unreal Engine 3 looks perhaps 10 times better than in the previous generation, but it's taking 3-4 times longer to model such high-polygon objects. Our art requirements are approaching what you see in movies; they are perhaps a factor of 4 lower right now, but in the two previous generations our detail was tens and hundreds of times lower!

Most development studios already have a 2-to-1 ratio of artists to programmers. I expect this ratio to continue to grow.</a>

<q>Do you see these new demands on artists pushing a lot of smaller gaming companies out of business?</q>

<a>The great thing about game development is that there are a broad spectrum of opportunities available for developers, from 1-3 person teams creating Nintendo GBA games, 5-10 person teams developing budget PC games, 10-20 person teams creating smaller PC and console games, and then the big leagues of 25-60 person teams creating triple-A games for PC and console. Arguably, the massive multiplayer games are a step above that. In addition, there are mod teams aspiring to "go commercial", and numerous startups looking for initial opportunities like add-on packs and contract development while building their teams.

The key to survival now is for developers to either do the right kind of project for their size and experience. If you're frustrated that you can't find a publisher to fund a 40-person startup you're trying to assemble, you're not being very realistic.

But from what we've seen among the early-adopter teams we've been working with as early Unreal Engine 3 licensees and evaluators, it's clear that a broad set of opportunities are out there for teams that are eager and realistic in their expectations.</a>

<q>Are there any good "3D capture" technologies available, e.g. a camera that can take a photo and triangulate it and upload it to 3D studio, for example? Do you envision such products ever (next decade or so) make a major impact in the game development world? </q>

<a>We looked into several off-the-shelf 3D capture solutions, and didn't find anything that was worth using. The polygon data they output is so rough that it typically requires more effort to clean-up the data than to create similar data from scratch using a modeling program. However, we just looked at the $5K-$20K solutions. There are $100K 3D laser scanners that might be better, but that's not necessarily a better solution that a modeling program.

Here, I ought to mention ZBrush, a modeling program that is truly a godsend in the new era of high-polygon modeling and normal-maping. If that didn't exist, we might bite the bullet and work more with the 3D capture tools.</a>

<q>The same thing for software in general. Software complexity has been Growing exponentially over the past decade or so but we are still using essentially the same programming language to develop most performance software. Do you see an end in sight or are there any new specialized languages or language features (other than DX9 obviously) which will dramatically reduce the code complexity of future projects? </q>

<a>Most major software today is developed in C++, with some tools often built in Java and C#. These languages have fairly poor complexity-scaling curves, and don't do anything to ease the use of multithreading, which will be critical shortly as Intel and AMD release dual-core CPU's in 2005.

While C++ certainly remains viable -- and, is realistically, the "least bad" solution available today -- I feel that we're approaching the same sort of diminishing returns that caused early developers to switch from Assembly Language to C, and then from C to C++. For the coming generation, we can and well get by just fine with C++, but I feel a consensus will emerge around the end of the decade that current development approaches are broken and need to be rethought.

Unfortunately, there isn't a clear successor to C++ lined up. Java and C# had their chance and it became clear that, while they simplify some aspects of development, they don't put us on the wholly new effort/reward curve the industry needs to be on, especially as relates to graphics and other forms of parallel processing, and multithreading. So the next transition could be very interesting. </a>

<q>Pixel Shaders seem to be the all the rage at the moment. What do you see as the next "big leap" in the 3D hardware world? Do you see CPUs becoming so powerful in the next 10 - 15 years that specialized 3D hardware will no longer become necessary?</q>

<a>Unreal Engine 1's software renderer is the programming project I'm the most proud of, so I have a special appreciation for this question. In an interview in 1999 (<a href="http://archive.gamespy.com/legacy/interviews/sweeney.shtm">http://archive.gamespy.com/legacy/interviews/sweeney.shtm</a>), I predicted that CPU's and 3D accelerators were on a collision course that would be apparent by 2007.

But that was before programmable shaders, high-level shading languages, and floating-point pixel processing existed! So, I don't think many people would take that prediction seriously today. But from time to time, developers do need to evaluate the question of whether to implement a given algorithm on either a CPU or GPU. Because as GPU's increase in generality, they are more capable of doing things beyond ordinary texture mapping, while CPU's have unparalleled performance for random-access, branch-intensive operations. </a>

<q>Do you think the differences in the approaches ATI and NVIDIA use for AA and anisotropic filtering are of any consequence in actual gameplay? </q>

<a>I see anisotropic filtering as clearly worthwhile and uncontroversial in all gaming, since it's inexpensive on average, and it improves the worst-case blurring of stretched textures significantly.

But I remain somewhat of a skeptic on the various forms of multisample antialiasing. These techniques are costly, often cause visual anomalies when enabled on an application without its knowledge. And in next-generation games, it's not clear that it is worthwhile to focus so much hardware on solving the edge-aliasing problem when the interior-aliasing problem is at least as significant. Once you move to next-generation per-pixel lighting models, the lighting equations (such as exponential specular lighting) are nonlinear, such that texture mipmap filtering doesn't avoid aliasing as is the case with linear diffuse lighting. </a>